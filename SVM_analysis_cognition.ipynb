{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d2172b-296d-4937-a055-edae4ddd75b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing and set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b707d-f761-4cf7-be4d-6622886a24ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## compile data (features and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c2927-6055-440d-bcf0-50e24f3ccdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from itertools import combinations\n",
    "from scipy.signal import butter, filtfilt\n",
    "from glob import glob\n",
    "\n",
    "# thresholds and range for motion\n",
    "threshold = 0.09 # filtered FD threshold\n",
    "notch_low = 18/60 # breaths per second, lower range\n",
    "notch_high = 30/60 # breaths per second, higher range\n",
    "\n",
    "# set up file paths\n",
    "proj_home = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/MoviesVsRest'\n",
    "data_dir = os.path.join(proj_home, 'DATA','cens09filtFD')\n",
    "\n",
    "# load sample information\n",
    "sample_info = pd.read_csv(os.path.join(proj_home, 'sample_information','HBN_MRI_DATA_TRACKER_20220102.csv'), \n",
    "                          index_col=0, na_values='n')\n",
    "sample_info = sample_info.loc[sample_info[['movieDM','movieTP','rest_run-1','rest_run-2']].sum(axis=1)>=1,\n",
    "                              ['release_number','Sex','Age','EHQ_Total','site']]\n",
    "sample_info.index = ['sub-{0}'.format(s) for s in sample_info.index]\n",
    "sample_info.index.name = 'sub'\n",
    "sample_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215919a0-7934-42f2-a94f-71c103fb7c43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_labels = pd.DataFrame()\n",
    "pconns = []\n",
    "idx = 0\n",
    "\n",
    "for s in sample_info.index:\n",
    "    for context in ['movie','rest']:\n",
    "        ts = os.path.join(data_dir, 'ptseries', '{0}_{1}_gordon.32k_fs_LR.ptseries.nii'.format(s, context))\n",
    "        conn = os.path.join(data_dir, 'pconns', '{0}_{1}_gordon.32k_fs_LR.pconn.nii'.format(s, context))\n",
    "        if os.path.isfile(ts):\n",
    "            temp = nib.load(conn).get_fdata()[:333,:333]\n",
    "            pconns.append(np.expand_dims(temp, axis=2))\n",
    "            TR = nib.load(ts).header.get_axis(0).step\n",
    "            dur = nib.load(ts).header.get_axis(0).size\n",
    "            fs = 1/TR\n",
    "\n",
    "            data_labels.loc[idx, 'sub'] = s\n",
    "            data_labels.loc[idx, 'context'] = context\n",
    "            data_labels.loc[idx, 'seconds_usable'] = dur*TR\n",
    "            \n",
    "            mot = glob(os.path.join(data_dir, 'motion', \n",
    "                                    '{0}_task-{1}*_bold1_AP_Movement_Regressors_dt.txt'.format(s, context)))\n",
    "            mot_data = []\n",
    "            for m in mot:\n",
    "                motion = np.loadtxt(m)[:,6:]\n",
    "                motion[:,3:] = 50*(np.pi/180)*motion[:,3:]\n",
    "                notchb, notcha = butter(2, [notch_low, notch_high], 'bandstop', fs=fs)\n",
    "                motion = filtfilt(notchb, notcha, motion, axis=0)\n",
    "                mot_data.append(motion)\n",
    "\n",
    "            if len(mot_data)>1:\n",
    "                motion = np.concatenate(mot_data, axis=0)\n",
    "            else:\n",
    "                motion = mot_data[0]\n",
    "\n",
    "            # identify volumes to censor\n",
    "            fd = np.sum(np.absolute(motion),axis=1)\n",
    "            vols_to_censor = fd>threshold\n",
    "            fd_cens = fd[vols_to_censor==0] \n",
    "\n",
    "            # add motion metrics to spreadsheet\n",
    "            data_labels.loc[idx, 'rawFD'] = np.mean(fd)\n",
    "            data_labels.loc[idx, 'censFD'] = np.mean(fd_cens)\n",
    "            data_labels.loc[idx, 'Nvolscens'] = np.sum(vols_to_censor)\n",
    "\n",
    "            idx += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b68f4-cffc-4490-8c0f-254140493ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cognitive scores\n",
    "cog = pd.read_csv(os.path.join(proj_home, 'cog_EFA','Cog_EFA_factorscores.csv'), index_col=0)\n",
    "cog.index = ['sub-{0}'.format(s) for s in cog.index]\n",
    "cog.index.name = 'sub'\n",
    "\n",
    "data_labels.index = data_labels['sub']\n",
    "data_labels = data_labels.merge(sample_info, how=\"left\", left_index=True, right_index=True)\n",
    "data_labels = data_labels.merge(cog, how=\"left\", left_index=True, right_index=True)\n",
    "data_labels.to_csv(os.path.join(data_dir, 'data_labels.csv'))\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be01612-7988-4558-914b-c9db683761fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 3D connectivity data\n",
    "group_pconns = np.concatenate(pconns, axis=2)\n",
    "print(group_pconns.shape)\n",
    "np.save(os.path.join(data_dir, 'pconn_data_3d.npy'), group_pconns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc031c-fe66-4e82-9019-905cdc0ef2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and save data\n",
    "conn = os.path.join(data_dir, 'pconns', '{0}_movie_gordon.32k_fs_LR.pconn.nii'.format(s))\n",
    "labels = nib.load(conn).header.get_axis(1).name[:-19]\n",
    "combs = combinations(labels,2)\n",
    "flat_data = pd.DataFrame(index = data_labels.index)\n",
    "\n",
    "for c in combs:\n",
    "    labA = c[0]\n",
    "    locA = np.where(labels==labA)[0][0]\n",
    "    labB = c[1]\n",
    "    locB = np.where(labels==labB)[0][0]\n",
    "    flat_data.loc[:, '{0}-{1}'.format(labA, labB)] = group_pconns[locA, locB, :]\n",
    "\n",
    "flat_data.to_csv(os.path.join(data_dir, 'pconn_data_2d.csv'))\n",
    "np.save(os.path.join(data_dir, 'pconn_data_2d.npy'), flat_data.to_numpy())\n",
    "flat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aef553-8489-4753-805a-6903b48e1fcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Are cognitive scores associated with age, sex, or motion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826130db-c64f-4220-b19a-b422030040fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scp\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='white')\n",
    "\n",
    "# set up file paths\n",
    "proj_home = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/MoviesVsRest'\n",
    "data_dir = os.path.join(proj_home, 'DATA','cens09filtFD')\n",
    "\n",
    "# load data\n",
    "data_labels = pd.read_csv(os.path.join(data_dir, 'data_labels.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d376dcc-214e-4382-b0f3-1a789fd99b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for context in ['movie','rest']:\n",
    "    temp = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), :]\n",
    "    \n",
    "    print('------------------ {0} ----------------'.format(context))\n",
    "    for cov in ['rawFD','censFD','Nvolscens','Age']:\n",
    "        # correlations\n",
    "        r, p = scp.spearmanr(temp[cov], temp['Cog1'], nan_policy='omit')\n",
    "        print('Cog1 and {0}: r={1}, p={2}.'.format(cov, round(r,2), round(p,3)))\n",
    "        sns.lmplot(x='Cog1', y=cov, data=temp, ci=None, line_kws={'color':'k', 'lw':4}, \n",
    "                   scatter_kws={'color':'gray', 'alpha':0.3})\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    # Sex differences\n",
    "    t, p = scp.ttest_ind(temp.loc[temp['Sex']==1, 'Cog1'], temp.loc[temp['Sex']==0, 'Cog1'], nan_policy='omit')\n",
    "    print('Cog1 and Sex: t={1}, p={2}.'.format(cov, round(t,2), round(p,3)))\n",
    "    sns.boxplot(x='Sex', y='Cog1', data=temp)\n",
    "    sns.stripplot(x='Sex', y='Cog1', data=temp,\n",
    "                  size=4, color='k', alpha=0.4, linewidth=0)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccee72-9ae9-40fe-a4b9-9bc9ce873645",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis: Can we predict cognitive scores from connectivity values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494e49c-edae-4507-8af8-96d60865e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scp\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from SVR_functions import cv_fit, predict_out, make_consistency_plot, boot_predict, permuted_p, permuted_importance, regress_covariates\n",
    "sns.set(context='paper', style='white')\n",
    "\n",
    "# set up file paths\n",
    "proj_home = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/MoviesVsRest'\n",
    "data_dir = os.path.join(proj_home, 'DATA','cens09filtFD')\n",
    "results_dir = os.path.join(proj_home, 'RESULTS','cens09filtFD')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# load data\n",
    "data = np.load(os.path.join(data_dir, 'pconn_data_2d.npy'))\n",
    "data_labels = pd.read_csv(os.path.join(data_dir, 'data_labels.csv'), index_col=0)\n",
    "edge_labels = pd.read_csv(os.path.join(data_dir, 'pconn_data_2d.csv'), index_col=0).columns.to_list()\n",
    "\n",
    "# limit data to participants with at least 300s of data\n",
    "data = data[data_labels['seconds_usable']>=300]\n",
    "data_labels = data_labels.loc[data_labels['seconds_usable']>=300,:]\n",
    "data_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02e667-59bf-464f-9035-8a96af3798a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over movie/rest\n",
    "for context in ['movie','rest']:\n",
    "    out_folder = os.path.join(results_dir, 'min300s_regress_cov', 'Cog1', context)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    model = SVR(kernel='linear')\n",
    "    cv = 10\n",
    "    \n",
    "    # split data to train/test\n",
    "    X = data[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1']))]\n",
    "    Y = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), 'Cog1'].to_numpy()\n",
    "\n",
    "    # remove covariates from data and labels\n",
    "    X_covs = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), ['Age','Sex','rawFD']]\n",
    "    X_covs = StandardScaler().fit_transform(X_covs)\n",
    "    X = regress_covariates(X, X_covs)\n",
    "    Y_covs = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), ['Age','Sex']]\n",
    "    Y_covs = StandardScaler().fit_transform(Y_covs)\n",
    "    Y = regress_covariates(Y, Y_covs)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    print('{0} train sample N={1}, test sample N={2}'.format(context, len(Y_train), len(Y_test)))\n",
    "    \n",
    "    # train model\n",
    "    estimators, weights, mean_weights, Y_pred_train, train_scores = cv_fit(model, X_train, Y_train, cv)\n",
    "    \n",
    "    # test model\n",
    "    Y_pred_test, accuracy = predict_out(X_test, Y_test, estimators, 'regress')\n",
    "    accuracy.to_csv(os.path.join(out_folder,'test_accuracy.csv'))\n",
    "    if not os.path.isfile(os.path.join(out_folder, 'bootstrapped_test_accuracy_randN.csv')):\n",
    "        boot_predict(estimators, X_test, Y_test, out_folder, samples=1000)\n",
    "    if not os.path.isfile(os.path.join(out_folder, 'permutation_score_distribution.npy')):\n",
    "        results = permuted_p(model, X_train, Y_train, cv, out_folder, np.mean(train_scores), -accuracy.loc['MSE','stat'])\n",
    "    permuted_importance(estimators, X_train, Y_train, edge_labels, out_folder)\n",
    "    \n",
    "    # plot results\n",
    "    plot_file_name = os.path.join(out_folder, 'testing_data_consistency.svg')\n",
    "    make_consistency_plot(Y_test, Y_pred_test, cv, plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6003c5c-19f2-4bf8-9aef-18e53008b558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
