{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d2172b-296d-4937-a055-edae4ddd75b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Processing and set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b707d-f761-4cf7-be4d-6622886a24ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## compile data (features and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c2927-6055-440d-bcf0-50e24f3ccdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from itertools import combinations\n",
    "from scipy.signal import butter, filtfilt\n",
    "from glob import glob\n",
    "\n",
    "# thresholds and range for motion\n",
    "threshold = 0.09 # filtered FD threshold\n",
    "notch_low = 18/60 # breaths per second, lower range\n",
    "notch_high = 30/60 # breaths per second, higher range\n",
    "\n",
    "# set up file paths\n",
    "proj_home = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/MoviesVsRest'\n",
    "data_dir = os.path.join(proj_home, 'DATA','cens09filtFD')\n",
    "\n",
    "# load sample information\n",
    "sample_info = pd.read_csv(os.path.join(proj_home, 'sample_information','HBN_MRI_DATA_TRACKER_20220102.csv'), \n",
    "                          index_col=0, na_values='n')\n",
    "sample_info = sample_info.loc[sample_info[['movieDM','movieTP','rest_run-1','rest_run-2']].sum(axis=1)>=1,\n",
    "                              ['release_number','Sex','Age','EHQ_Total','site']]\n",
    "sample_info.index = ['sub-{0}'.format(s) for s in sample_info.index]\n",
    "sample_info.index.name = 'sub'\n",
    "sample_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215919a0-7934-42f2-a94f-71c103fb7c43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_labels = pd.DataFrame()\n",
    "pconns = []\n",
    "idx = 0\n",
    "\n",
    "for s in sample_info.index:\n",
    "    for context in ['movie','rest']:\n",
    "        ts = os.path.join(data_dir, 'ptseries', '{0}_{1}_gordon.32k_fs_LR.ptseries.nii'.format(s, context))\n",
    "        conn = os.path.join(data_dir, 'pconns', '{0}_{1}_gordon.32k_fs_LR.pconn.nii'.format(s, context))\n",
    "        if os.path.isfile(ts):\n",
    "            temp = nib.load(conn).get_fdata()[:333,:333]\n",
    "            pconns.append(np.expand_dims(temp, axis=2))\n",
    "            TR = nib.load(ts).header.get_axis(0).step\n",
    "            dur = nib.load(ts).header.get_axis(0).size\n",
    "            fs = 1/TR\n",
    "\n",
    "            data_labels.loc[idx, 'sub'] = s\n",
    "            data_labels.loc[idx, 'context'] = context\n",
    "            data_labels.loc[idx, 'seconds_usable'] = dur*TR\n",
    "            \n",
    "            mot = glob(os.path.join(data_dir, 'motion', \n",
    "                                    '{0}_task-{1}*_bold1_AP_Movement_Regressors_dt.txt'.format(s, context)))\n",
    "            mot_data = []\n",
    "            for m in mot:\n",
    "                motion = np.loadtxt(m)[:,6:]\n",
    "                motion[:,3:] = 50*(np.pi/180)*motion[:,3:]\n",
    "                notchb, notcha = butter(2, [notch_low, notch_high], 'bandstop', fs=fs)\n",
    "                motion = filtfilt(notchb, notcha, motion, axis=0)\n",
    "                mot_data.append(motion)\n",
    "\n",
    "            if len(mot_data)>1:\n",
    "                motion = np.concatenate(mot_data, axis=0)\n",
    "            else:\n",
    "                motion = mot_data[0]\n",
    "\n",
    "            # identify volumes to censor\n",
    "            fd = np.sum(np.absolute(motion),axis=1)\n",
    "            vols_to_censor = fd>threshold\n",
    "            fd_cens = fd[vols_to_censor==0] \n",
    "\n",
    "            # add motion metrics to spreadsheet\n",
    "            data_labels.loc[idx, 'rawFD'] = np.mean(fd)\n",
    "            data_labels.loc[idx, 'censFD'] = np.mean(fd_cens)\n",
    "            data_labels.loc[idx, 'Nvolscens'] = np.sum(vols_to_censor)\n",
    "\n",
    "            idx += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b68f4-cffc-4490-8c0f-254140493ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cognitive scores\n",
    "cog = pd.read_csv(os.path.join(proj_home, 'cog_EFA','Cog_EFA_factorscores.csv'), index_col=0)\n",
    "cog.index = ['sub-{0}'.format(s) for s in cog.index]\n",
    "cog.index.name = 'sub'\n",
    "\n",
    "data_labels.index = data_labels['sub']\n",
    "data_labels = data_labels.merge(sample_info, how=\"left\", left_index=True, right_index=True)\n",
    "data_labels = data_labels.merge(cog, how=\"left\", left_index=True, right_index=True)\n",
    "data_labels.to_csv(os.path.join(data_dir, 'data_labels.csv'))\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be01612-7988-4558-914b-c9db683761fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 3D connectivity data\n",
    "group_pconns = np.concatenate(pconns, axis=2)\n",
    "print(group_pconns.shape)\n",
    "np.save(os.path.join(data_dir, 'pconn_data_3d.npy'), group_pconns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc031c-fe66-4e82-9019-905cdc0ef2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten and save data\n",
    "conn = os.path.join(data_dir, 'pconns', '{0}_movie_gordon.32k_fs_LR.pconn.nii'.format(s))\n",
    "labels = nib.load(conn).header.get_axis(1).name[:-19]\n",
    "combs = combinations(labels,2)\n",
    "flat_data = pd.DataFrame(index = data_labels.index)\n",
    "\n",
    "for c in combs:\n",
    "    labA = c[0]\n",
    "    locA = np.where(labels==labA)[0][0]\n",
    "    labB = c[1]\n",
    "    locB = np.where(labels==labB)[0][0]\n",
    "    flat_data.loc[:, '{0}-{1}'.format(labA, labB)] = group_pconns[locA, locB, :]\n",
    "\n",
    "flat_data.to_csv(os.path.join(data_dir, 'pconn_data_2d.csv'))\n",
    "np.save(os.path.join(data_dir, 'pconn_data_2d.npy'), flat_data.to_numpy())\n",
    "flat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aef553-8489-4753-805a-6903b48e1fcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Are cognitive scores associated with age, sex, or motion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826130db-c64f-4220-b19a-b422030040fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scp\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='white')\n",
    "\n",
    "# set up file paths\n",
    "proj_home = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/MoviesVsRest'\n",
    "data_dir = os.path.join(proj_home, 'DATA','cens09filtFD')\n",
    "\n",
    "# load data\n",
    "data_labels = pd.read_csv(os.path.join(data_dir, 'data_labels.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d376dcc-214e-4382-b0f3-1a789fd99b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for context in ['movie','rest']:\n",
    "    temp = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), :]\n",
    "    \n",
    "    print('------------------ {0} ----------------'.format(context))\n",
    "    for cov in ['rawFD','censFD','Nvolscens','Age']:\n",
    "        # correlations\n",
    "        r, p = scp.spearmanr(temp[cov], temp['Cog1'], nan_policy='omit')\n",
    "        print('Cog1 and {0}: r={1}, p={2}.'.format(cov, round(r,2), round(p,3)))\n",
    "        sns.lmplot(x='Cog1', y=cov, data=temp, ci=None, line_kws={'color':'k', 'lw':4}, \n",
    "                   scatter_kws={'color':'gray', 'alpha':0.3})\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    # Sex differences\n",
    "    t, p = scp.ttest_ind(temp.loc[temp['Sex']==1, 'Cog1'], temp.loc[temp['Sex']==0, 'Cog1'], nan_policy='omit')\n",
    "    print('Cog1 and Sex: t={1}, p={2}.'.format(cov, round(t,2), round(p,3)))\n",
    "    sns.boxplot(x='Sex', y='Cog1', data=temp)\n",
    "    sns.stripplot(x='Sex', y='Cog1', data=temp,\n",
    "                  size=4, color='k', alpha=0.4, linewidth=0)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccee72-9ae9-40fe-a4b9-9bc9ce873645",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis: Can we predict cognitive scores from connectivity values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1494e49c-edae-4507-8af8-96d60865e3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds_usable</th>\n",
       "      <th>rawFD</th>\n",
       "      <th>censFD</th>\n",
       "      <th>Nvolscens</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>EHQ_Total</th>\n",
       "      <th>Cog1</th>\n",
       "      <th>Cog2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1026.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>474.903502</td>\n",
       "      <td>0.117349</td>\n",
       "      <td>0.050860</td>\n",
       "      <td>296.934825</td>\n",
       "      <td>0.393969</td>\n",
       "      <td>10.819344</td>\n",
       "      <td>61.775361</td>\n",
       "      <td>5.388676</td>\n",
       "      <td>1.708382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>119.107562</td>\n",
       "      <td>0.069236</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>159.008738</td>\n",
       "      <td>0.488866</td>\n",
       "      <td>2.713989</td>\n",
       "      <td>49.569358</td>\n",
       "      <td>1.995708</td>\n",
       "      <td>0.334919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.061259</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.861285</td>\n",
       "      <td>0.877491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>376.600000</td>\n",
       "      <td>0.072819</td>\n",
       "      <td>0.046675</td>\n",
       "      <td>176.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.630817</td>\n",
       "      <td>50.285000</td>\n",
       "      <td>3.891126</td>\n",
       "      <td>1.467506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>459.200000</td>\n",
       "      <td>0.098973</td>\n",
       "      <td>0.051845</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.703684</td>\n",
       "      <td>80.040000</td>\n",
       "      <td>5.486198</td>\n",
       "      <td>1.691122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>552.800000</td>\n",
       "      <td>0.139418</td>\n",
       "      <td>0.055775</td>\n",
       "      <td>402.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.088523</td>\n",
       "      <td>96.402500</td>\n",
       "      <td>7.014392</td>\n",
       "      <td>1.940749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>789.600000</td>\n",
       "      <td>0.559902</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.987451</td>\n",
       "      <td>100.050000</td>\n",
       "      <td>9.183065</td>\n",
       "      <td>3.005091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seconds_usable        rawFD       censFD    Nvolscens          Sex  \\\n",
       "count     1028.000000  1028.000000  1028.000000  1028.000000  1028.000000   \n",
       "mean       474.903502     0.117349     0.050860   296.934825     0.393969   \n",
       "std        119.107562     0.069236     0.006995   159.008738     0.488866   \n",
       "min        300.000000     0.023551     0.021643     7.000000     0.000000   \n",
       "25%        376.600000     0.072819     0.046675   176.750000     0.000000   \n",
       "50%        459.200000     0.098973     0.051845   283.000000     0.000000   \n",
       "75%        552.800000     0.139418     0.055775   402.000000     1.000000   \n",
       "max        789.600000     0.559902     0.065634   625.000000     1.000000   \n",
       "\n",
       "               Age    EHQ_Total        Cog1        Cog2  \n",
       "count  1028.000000  1026.000000  944.000000  944.000000  \n",
       "mean     10.819344    61.775361    5.388676    1.708382  \n",
       "std       2.713989    49.569358    1.995708    0.334919  \n",
       "min       5.061259  -100.000000    0.861285    0.877491  \n",
       "25%       8.630817    50.285000    3.891126    1.467506  \n",
       "50%      10.703684    80.040000    5.486198    1.691122  \n",
       "75%      13.088523    96.402500    7.014392    1.940749  \n",
       "max      15.987451   100.050000    9.183065    3.005091  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scp\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from SVR_functions import cv_fit, predict_out, make_consistency_plot, boot_predict, permuted_p, permuted_importance, regress_covariates\n",
    "sns.set(context='paper', style='white')\n",
    "\n",
    "# set up file paths\n",
    "proj_home = '/Users/catcamacho/Library/CloudStorage/Box-Box/CCP/HBN_study/MoviesVsRest'\n",
    "data_dir = os.path.join(proj_home, 'DATA','cens09filtFD')\n",
    "results_dir = os.path.join(proj_home, 'RESULTS','cens09filtFD')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# load data\n",
    "data = np.load(os.path.join(data_dir, 'pconn_data_2d.npy'))\n",
    "data_labels = pd.read_csv(os.path.join(data_dir, 'data_labels.csv'), index_col=0)\n",
    "edge_labels = pd.read_csv(os.path.join(data_dir, 'pconn_data_2d.csv'), index_col=0).columns.to_list()\n",
    "\n",
    "# limit data to participants with at least 300s of data\n",
    "data = data[data_labels['seconds_usable']>=300]\n",
    "data_labels = data_labels.loc[data_labels['seconds_usable']>=300,:]\n",
    "data_labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa02e667-59bf-464f-9035-8a96af3798a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie train sample N=439, test sample N=110\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "No loop matching the specified signature and casting was found for ufunc add",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c_/ms_vv4qx13d2z86m53sfcf1m0000gq/T/ipykernel_1439/1393368785.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mY_pred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'regress'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test_accuracy.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bootstrapped_test_accuracy_randN.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Mac/Documents/GitHub/movies_vs_rest/SVR_functions.py\u001b[0m in \u001b[0;36mpredict_out\u001b[0;34m(X, Y, estimators, kind)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpearmanR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpearmanR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PearsonR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PearsonR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinregress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LinearB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   4032\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4034\u001b[0;31m     \u001b[0mxmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4035\u001b[0m     \u001b[0mymean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: No loop matching the specified signature and casting was found for ufunc add"
     ]
    }
   ],
   "source": [
    "# loop over movie/rest\n",
    "for context in ['movie','rest']:\n",
    "    out_folder = os.path.join(results_dir, 'min300s_regress_cov', 'Cog1', context)\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    model = SVR(kernel='linear')\n",
    "    cv = 10\n",
    "    \n",
    "    # split data to train/test\n",
    "    X = data[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1']))]\n",
    "    Y = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), 'Cog1'].to_numpy()\n",
    "\n",
    "    # remove covariates from data and labels\n",
    "    X_covs = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), ['Age','Sex','rawFD']]\n",
    "    X_covs = StandardScaler().fit_transform(X_covs)\n",
    "    X = regress_covariates(X, X_covs)\n",
    "    Y_covs = data_labels.loc[(data_labels['context']==context) & (np.isfinite(data_labels['Cog1'])), ['Age','Sex']]\n",
    "    Y_covs = StandardScaler().fit_transform(Y_covs)\n",
    "    Y = regress_covariates(Y, Y_covs)\n",
    "    \n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    print('{0} train sample N={1}, test sample N={2}'.format(context, len(Y_train), len(Y_test)))\n",
    "    \n",
    "    # train model\n",
    "    estimators, weights, mean_weights, Y_pred_train, train_scores = cv_fit(model, X_train, Y_train, cv)\n",
    "    \n",
    "    # test model\n",
    "    Y_pred_test, accuracy = predict_out(X_test, Y_test, estimators, 'regress')\n",
    "    accuracy.to_csv(os.path.join(out_folder,'test_accuracy.csv'))\n",
    "    if not os.path.isfile(os.path.join(out_folder, 'bootstrapped_test_accuracy_randN.csv')):\n",
    "        boot_predict(estimators, X_test, Y_test, out_folder, samples=1000)\n",
    "    if not os.path.isfile(os.path.join(out_folder, 'permutation_score_distribution.npy')):\n",
    "        results = permuted_p(model, X_train, Y_train, cv, out_folder, np.mean(train_scores), -accuracy.loc['MSE','stat'])\n",
    "    permuted_importance(estimators, X_train, Y_train, edge_labels, out_folder)\n",
    "    \n",
    "    # plot results\n",
    "    plot_file_name = os.path.join(out_folder, 'testing_data_consistency.svg')\n",
    "    make_consistency_plot(Y_test, Y_pred_test, cv, plot_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6003c5c-19f2-4bf8-9aef-18e53008b558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
